{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PerfPro FIT files EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import zipfile\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import fitparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the zipped files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the .fit files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_read_zip_files = r'D:\\perfpro_data\\raw'\n",
    "path_to_extract_zip_files = r'D:\\perfpro_data\\extracted'\n",
    "\n",
    "zip_files = [f for f in listdir(path_to_read_zip_files) if isfile(join(path_to_read_zip_files, f))]\n",
    "\n",
    "for file in zip_files:\n",
    "    with zipfile.ZipFile(join(path_to_read_zip_files, file), 'r') as zip_ref:        \n",
    "        for file_name in zip_ref.namelist():\n",
    "            if file_name.endswith('.fit'):\n",
    "                 zip_ref.extract(file_name, path_to_extract_zip_files)\n",
    "                 \n",
    "fit_files = [f for f in listdir(path_to_extract_zip_files) if isfile(join(path_to_extract_zip_files, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process .fit files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_file_to_pandas(file_path):\n",
    "    fitfile = fitparse.FitFile(file_path)\n",
    "    # Iterate over all messages of type \"record\"\n",
    "    # (other types include \"device_info\", \"file_creator\", \"event\", etc)\n",
    "    file_data = []\n",
    "    for record in fitfile.get_messages(\"record\"):\n",
    "        # Gets the record timestamp\n",
    "        timestamp = next((x for x in record.fields if x.name == 'timestamp'), None)\n",
    "        if timestamp is not None:\n",
    "            for data in record:\n",
    "                # Print the name and value of the data (and the units if it has any)\n",
    "                if data.name != 'timestamp':\n",
    "                    if data.units:\n",
    "                        file_data.append((timestamp.value, data.name, data.value, data.units))\n",
    "                    else:\n",
    "                        file_data.append((timestamp.value, data.name, data.value, None))\n",
    "\n",
    "    file_data_df = pd.DataFrame(file_data, columns=['timestamp', 'name', 'value', 'unit'])\n",
    "    return file_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table train_fit_values has 6 columns but 5 values were supplied",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8664/1285837230.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtrain_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mfile_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mmd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_train_fit_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\cycling-analytics\\analytics\\historical\\data_model.py\u001b[0m in \u001b[0;36msave_train_fit_values\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutemany\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'INSERT INTO train_fit_values(timestamp,variable,value,unit,train_id) VALUES (?,?,?,?,?)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIntegrityError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: table train_fit_values has 6 columns but 5 values were supplied"
     ]
    }
   ],
   "source": [
    "# parse all files to the database\n",
    "from data_model import CyclingAnalyticsDataModel\n",
    "# create the data model\n",
    "db_file = r'D:\\perfpro_data\\history.db'\n",
    "md = CyclingAnalyticsDataModel(db_file)\n",
    "\n",
    "for fit_file in fit_files:\n",
    "    file_path = join(path_to_extract_zip_files, fit_file)\n",
    "    file_df = fit_file_to_pandas(file_path)\n",
    "    fit_file_fields = fit_file.split(\"-\")\n",
    "    \n",
    "    user = fit_file_fields[0]\n",
    "    train_id = md.create_train(fit_file, user=user)\n",
    "    file_df['train_id'] = train_id\n",
    "    md.save_train_fit_values(file_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bebdc1563427ae82f1bcd5d3d2948a34251dcf7af89a419da8f2b9c5e387a065"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('dev-cycling-analytics': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
